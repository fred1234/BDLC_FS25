{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "258b6ec1-c698-41b2-9218-b592be1f116e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16 items\n",
      "drwxr-xr-x   - cluster supergroup          0 2025-04-12 12:46 /taxi/raw/2009\n",
      "drwxr-xr-x   - cluster supergroup          0 2025-04-12 12:50 /taxi/raw/2010\n",
      "drwxr-xr-x   - cluster supergroup          0 2025-04-12 12:51 /taxi/raw/2011\n",
      "drwxr-xr-x   - cluster supergroup          0 2025-04-12 12:52 /taxi/raw/2012\n",
      "drwxr-xr-x   - cluster supergroup          0 2025-04-12 12:54 /taxi/raw/2013\n",
      "drwxr-xr-x   - cluster supergroup          0 2025-04-12 12:55 /taxi/raw/2014\n",
      "drwxr-xr-x   - cluster supergroup          0 2025-04-12 12:29 /taxi/raw/2015\n",
      "drwxr-xr-x   - cluster supergroup          0 2025-04-12 12:31 /taxi/raw/2016\n",
      "drwxr-xr-x   - cluster supergroup          0 2025-04-12 12:32 /taxi/raw/2017\n",
      "drwxr-xr-x   - cluster supergroup          0 2025-04-12 12:33 /taxi/raw/2018\n",
      "drwxr-xr-x   - cluster supergroup          0 2025-04-12 12:34 /taxi/raw/2019\n",
      "drwxr-xr-x   - cluster supergroup          0 2025-04-12 12:34 /taxi/raw/2020\n",
      "drwxr-xr-x   - cluster supergroup          0 2025-04-12 12:35 /taxi/raw/2021\n",
      "drwxr-xr-x   - cluster supergroup          0 2025-04-12 12:35 /taxi/raw/2022\n",
      "drwxr-xr-x   - cluster supergroup          0 2025-04-12 12:36 /taxi/raw/2023\n",
      "drwxr-xr-x   - cluster supergroup          0 2025-04-12 12:36 /taxi/raw/2024\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /taxi/raw/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "282da660-8581-4c24-89d0-512977f71efc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/12 15:09:40 WARN Utils: Your hostname, bdlc-002 resolves to a loopback address: 127.0.1.1; using 10.176.129.5 instead (on interface ens192)\n",
      "25/04/12 15:09:40 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/04/12 15:09:40 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"PreProcessing\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468fd368-6e9e-47e4-bb18-125ba4fff65a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# All Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121079b1-0188-4c47-9a80-e3d19e8e48bb",
   "metadata": {},
   "source": [
    "## Renaming Columns, Payment Types, Pick Columns, Casting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c298a9e5-4626-47eb-b4dc-eef49473662d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "df_all_raw = spark.read.parquet(f\"/taxi/raw/2019/yellow_tripdata_2019-01.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69707766-bfab-4b61-9524-cb09ae4a2c98",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|airport_fee|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "|       1| 2019-01-01 00:46:40|  2019-01-01 00:53:20|            1.0|          1.5|       1.0|                 N|         151|         239|           1|        7.0|  0.5|    0.5|      1.65|         0.0|                  0.3|        9.95|                NULL|       NULL|\n",
      "|       1| 2019-01-01 00:59:47|  2019-01-01 01:18:59|            1.0|          2.6|       1.0|                 N|         239|         246|           1|       14.0|  0.5|    0.5|       1.0|         0.0|                  0.3|        16.3|                NULL|       NULL|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_all_raw.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e10ddc92-fc7e-405b-8652-d7e36cf93709",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when, expr, col\n",
    "\n",
    "df = df_all_raw\\\n",
    ".withColumnRenamed(\"Trip_Pickup_DateTime\",\"pickup_datetime\")\\\n",
    ".withColumnRenamed(\"Trip_Dropoff_DateTime\",\"dropoff_datetime\")\\\n",
    ".withColumnRenamed(\"tpep_pickup_datetime\",\"pickup_datetime\")\\\n",
    ".withColumnRenamed(\"tpep_dropoff_datetime\",\"dropoff_datetime\")\\\n",
    ".withColumnRenamed(\"Passenger_Count\",\"passenger_count\")\\\n",
    ".withColumnRenamed(\"Trip_Distance\",\"trip_distance\")\\\n",
    ".withColumnRenamed(\"Payment_Type\",\"payment_type\")\\\n",
    ".withColumnRenamed(\"Tip_Amt\",\"tip_amount\")\\\n",
    ".withColumnRenamed(\"Total_Amt\",\"total_amount\")\\\n",
    ".withColumn('payment_type', \\\n",
    "              when(col(\"payment_type\") == \"Credit\", 1)\\\n",
    "              .when(col(\"payment_type\") == \"CREDIT\", 1)\\\n",
    "              .when(col(\"payment_type\") == \"CRD\", 1)\\\n",
    "              .when(col(\"payment_type\") == \"Cre\", 1)\\\n",
    "              .when(col(\"payment_type\") == \"CRE\", 1)\\\n",
    "              .when(col(\"payment_type\") == \"CASH\", 2)\\\n",
    "              .when(col(\"payment_type\") == \"Cash\", 2)\\\n",
    "              .when(col(\"payment_type\") == \"CSH\", 2)\\\n",
    "              .when(col(\"payment_type\") == \"CAS\", 2)\\\n",
    "              .when(col(\"payment_type\") == \"Cas\", 2)\\\n",
    "              .when(col(\"payment_type\") == \"No Charge\", 3)\\\n",
    "              .when(col(\"payment_type\") == \"NO CHARGE\", 3)\\\n",
    "              .when(col(\"payment_type\") == \"NOC\", 3)\\\n",
    "              .when(col(\"payment_type\") == \"NO \", 3)\\\n",
    "              .when(col(\"payment_type\") == \"Dispute\", 4)\\\n",
    "              .when(col(\"payment_type\") == \"DISPUTE\", 4)\\\n",
    "              .when(col(\"payment_type\") == \"DIS\", 4)\\\n",
    "              .when(col(\"payment_type\") == \"Dis\", 4)\\\n",
    "              .when(col(\"payment_type\") == \"Unknown\", 5)\\\n",
    "              .when(col(\"payment_type\") == \"UNKNOWN\", 5)\\\n",
    "              .when(col(\"payment_type\") == \"UNK\", 5)\\\n",
    "              .when(col(\"payment_type\") == \"Voided Trip\", 6)\\\n",
    "              .when(col(\"payment_type\") == \"VOIDED TRIP\", 6)\\\n",
    "              .otherwise(expr(\"payment_type\")))\\\n",
    ".selectExpr(\\\n",
    "    \"cast(pickup_datetime as timestamp)\", \\\n",
    "    \"cast(dropoff_datetime as timestamp)\", \\\n",
    "    \"cast(passenger_count as long)\", \\\n",
    "    \"trip_distance\", \\\n",
    "    \"cast(payment_type as string)\", \\\n",
    "    \"tip_amount\", \\\n",
    "    \"total_amount\" \\\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4be2c1a-2888-4e97-a205-f019d6bfbbac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+---------------+-------------+------------+----------+------------+\n",
      "|    pickup_datetime|   dropoff_datetime|passenger_count|trip_distance|payment_type|tip_amount|total_amount|\n",
      "+-------------------+-------------------+---------------+-------------+------------+----------+------------+\n",
      "|2019-01-01 00:46:40|2019-01-01 00:53:20|              1|          1.5|           1|      1.65|        9.95|\n",
      "|2019-01-01 00:59:47|2019-01-01 01:18:59|              1|          2.6|           1|       1.0|        16.3|\n",
      "+-------------------+-------------------+---------------+-------------+------------+----------+------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454915a8-8f6d-4ad3-b638-081a8e91dfff",
   "metadata": {},
   "source": [
    "## adding month/year as columns\n",
    "\n",
    "You can use `input_file_name` to get the filename of the dataframe. Here we have the month/year available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd8c43ca-45ad-4d8a-9749-3ae7638113ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+---------------+-------------+------------+----------+------------+-------------------------------------------------------------------------------------+\n",
      "|pickup_datetime    |dropoff_datetime   |passenger_count|trip_distance|payment_type|tip_amount|total_amount|filename                                                                             |\n",
      "+-------------------+-------------------+---------------+-------------+------------+----------+------------+-------------------------------------------------------------------------------------+\n",
      "|2019-01-01 00:46:40|2019-01-01 00:53:20|1              |1.5          |1           |1.65      |9.95        |hdfs://bdlc-002.bdlc.ls.eee.intern:9000/taxi/raw/2019/yellow_tripdata_2019-01.parquet|\n",
      "|2019-01-01 00:59:47|2019-01-01 01:18:59|1              |2.6          |1           |1.0       |16.3        |hdfs://bdlc-002.bdlc.ls.eee.intern:9000/taxi/raw/2019/yellow_tripdata_2019-01.parquet|\n",
      "+-------------------+-------------------+---------------+-------------+------------+----------+------------+-------------------------------------------------------------------------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import input_file_name\n",
    "\n",
    "df.withColumn(\"filename\", input_file_name()).show(2, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fca51c74-d913-4ab4-994a-baa559e4313a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+---------------+-------------+------------+----------+------------+-----------------------------------------------------------------------------------------+\n",
      "|pickup_datetime    |dropoff_datetime   |passenger_count|trip_distance|payment_type|tip_amount|total_amount|filename                                                                                 |\n",
      "+-------------------+-------------------+---------------+-------------+------------+----------+------------+-----------------------------------------------------------------------------------------+\n",
      "|2019-01-01 00:46:40|2019-01-01 00:53:20|1              |1.5          |1           |1.65      |9.95        |[hdfs://bdlc, 002.bdlc.ls.eee.intern:9000/taxi/raw/2019/yellow_tripdata_2019, 01.parquet]|\n",
      "|2019-01-01 00:59:47|2019-01-01 01:18:59|1              |2.6          |1           |1.0       |16.3        |[hdfs://bdlc, 002.bdlc.ls.eee.intern:9000/taxi/raw/2019/yellow_tripdata_2019, 01.parquet]|\n",
      "+-------------------+-------------------+---------------+-------------+------------+----------+------------+-----------------------------------------------------------------------------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import input_file_name, split\n",
    "\n",
    "df.withColumn(\"filename\", split(input_file_name(), \"-\")).show(2, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd20ca1c-a426-4bb8-b672-5409e2aa97f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df\\\n",
    ".withColumn(\"filename\", split(input_file_name(), \"-\"))\\\n",
    ".selectExpr(\"*\", \"substring_index(element_at(filename, 2), '_', -1) as year\", \"substring_index(element_at(filename, -1), '.' , 1) as month\")\\\n",
    ".drop(\"filename\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07e3b10a-4203-4da3-837f-adfb9a02d211",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+---------------+-------------+------------+----------+------------+----+-----+\n",
      "|    pickup_datetime|   dropoff_datetime|passenger_count|trip_distance|payment_type|tip_amount|total_amount|year|month|\n",
      "+-------------------+-------------------+---------------+-------------+------------+----------+------------+----+-----+\n",
      "|2019-01-01 00:46:40|2019-01-01 00:53:20|              1|          1.5|           1|      1.65|        9.95|2019|   01|\n",
      "|2019-01-01 00:59:47|2019-01-01 01:18:59|              1|          2.6|           1|       1.0|        16.3|2019|   01|\n",
      "+-------------------+-------------------+---------------+-------------+------------+----------+------------+----+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7aa1f14-b7b7-47da-9211-10952375791f",
   "metadata": {},
   "source": [
    "## convert trip distance to km instead of miles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c815236-0a6e-4510-8770-247c3627af9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import expr\n",
    "\n",
    "df = df.withColumn(\"trip_distance\", expr(\"trip_distance * 1.60934\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04136145-7451-4b81-93d9-bdaed1929262",
   "metadata": {},
   "source": [
    "## adding a field `trip_amount`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc3a02b3-8cb9-4459-b4a0-6d0148ad5c34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df.withColumn(\"trip_amount\", expr(\"total_amount-tip_amount\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ddd09e-fd14-4540-a126-9b7072251a6b",
   "metadata": {},
   "source": [
    "## Union Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "beecf5b9-20c7-448f-873f-a56070bcf62c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when, expr, col, input_file_name, split\n",
    "   \n",
    "def read(year, month):\n",
    "    df = spark.read.parquet(f\"/taxi/raw/{year}/yellow_tripdata_{year}-{month}.parquet\")\\\n",
    "    \n",
    "    df = df\\\n",
    "    .withColumnRenamed(\"Trip_Pickup_DateTime\",\"pickup_datetime\")\\\n",
    "    .withColumnRenamed(\"Trip_Dropoff_DateTime\",\"dropoff_datetime\")\\\n",
    "    .withColumnRenamed(\"tpep_pickup_datetime\",\"pickup_datetime\")\\\n",
    "    .withColumnRenamed(\"tpep_dropoff_datetime\",\"dropoff_datetime\")\\\n",
    "    .withColumnRenamed(\"Passenger_Count\",\"passenger_count\")\\\n",
    "    .withColumnRenamed(\"Trip_Distance\",\"trip_distance\")\\\n",
    "    .withColumnRenamed(\"Payment_Type\",\"payment_type\")\\\n",
    "    .withColumnRenamed(\"Tip_Amt\",\"tip_amount\")\\\n",
    "    .withColumnRenamed(\"Total_Amt\",\"total_amount\")\\\n",
    "    .withColumn('payment_type', \\\n",
    "                  when(col(\"payment_type\") == \"Credit\", 1)\\\n",
    "                  .when(col(\"payment_type\") == \"CREDIT\", 1)\\\n",
    "                  .when(col(\"payment_type\") == \"CRD\", 1)\\\n",
    "                  .when(col(\"payment_type\") == \"Cre\", 1)\\\n",
    "                  .when(col(\"payment_type\") == \"CRE\", 1)\\\n",
    "                  .when(col(\"payment_type\") == \"CASH\", 2)\\\n",
    "                  .when(col(\"payment_type\") == \"Cash\", 2)\\\n",
    "                  .when(col(\"payment_type\") == \"CSH\", 2)\\\n",
    "                  .when(col(\"payment_type\") == \"CAS\", 2)\\\n",
    "                  .when(col(\"payment_type\") == \"Cas\", 2)\\\n",
    "                  .when(col(\"payment_type\") == \"No Charge\", 3)\\\n",
    "                  .when(col(\"payment_type\") == \"NO CHARGE\", 3)\\\n",
    "                  .when(col(\"payment_type\") == \"NOC\", 3)\\\n",
    "                  .when(col(\"payment_type\") == \"NO \", 3)\\\n",
    "                  .when(col(\"payment_type\") == \"Dispute\", 4)\\\n",
    "                  .when(col(\"payment_type\") == \"DISPUTE\", 4)\\\n",
    "                  .when(col(\"payment_type\") == \"DIS\", 4)\\\n",
    "                  .when(col(\"payment_type\") == \"Dis\", 4)\\\n",
    "                  .when(col(\"payment_type\") == \"Unknown\", 5)\\\n",
    "                  .when(col(\"payment_type\") == \"UNKNOWN\", 5)\\\n",
    "                  .when(col(\"payment_type\") == \"UNK\", 5)\\\n",
    "                  .when(col(\"payment_type\") == \"Voided Trip\", 6)\\\n",
    "                  .when(col(\"payment_type\") == \"VOIDED TRIP\", 6)\\\n",
    "                  .otherwise(expr(\"payment_type\")))\\\n",
    "    .selectExpr(\\\n",
    "        \"cast(pickup_datetime as timestamp)\", \\\n",
    "        \"cast(dropoff_datetime as timestamp)\", \\\n",
    "        \"cast(passenger_count as long)\", \\\n",
    "        \"trip_distance\", \\\n",
    "        \"cast(payment_type as string)\", \\\n",
    "        \"tip_amount\", \\\n",
    "        \"total_amount\" \\\n",
    "    )\n",
    "    \n",
    "\n",
    "    df = df\\\n",
    "    .withColumn(\"filename\", split(input_file_name(), \"-\"))\\\n",
    "    .selectExpr(\"*\", \"substring_index(element_at(filename, 2), '_', -1) as year\", \"substring_index(element_at(filename, -1), '.' , 1) as month\")\\\n",
    "    .drop(\"filename\")\n",
    "    \n",
    "\n",
    "    df = df.withColumn(\"trip_distance\", expr(\"trip_distance * 1.60934\"))\n",
    "    df = df.withColumn(\"trip_amount\", expr(\"total_amount-tip_amount\"))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c51755d-8638-4d34-ba41-510b2bfcb77f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing 2009/01\n",
      "processing 2009/02\n",
      "processing 2009/03\n",
      "processing 2009/04\n",
      "processing 2009/05\n",
      "processing 2009/06\n",
      "processing 2009/07\n",
      "processing 2009/08\n",
      "processing 2009/09\n",
      "processing 2009/10\n",
      "processing 2009/11\n",
      "processing 2009/12\n",
      "processing 2010/01\n",
      "processing 2010/02\n",
      "processing 2010/03\n",
      "processing 2010/04\n",
      "processing 2010/05\n",
      "processing 2010/06\n",
      "processing 2010/07\n",
      "processing 2010/08\n",
      "processing 2010/09\n",
      "processing 2010/10\n",
      "processing 2010/11\n",
      "processing 2010/12\n",
      "processing 2011/01\n",
      "processing 2011/02\n",
      "processing 2011/03\n",
      "processing 2011/04\n",
      "processing 2011/05\n",
      "processing 2011/06\n",
      "processing 2011/07\n",
      "processing 2011/08\n",
      "processing 2011/09\n",
      "processing 2011/10\n",
      "processing 2011/11\n",
      "processing 2011/12\n",
      "processing 2012/01\n",
      "processing 2012/02\n",
      "processing 2012/03\n",
      "processing 2012/04\n",
      "processing 2012/05\n",
      "processing 2012/06\n",
      "processing 2012/07\n",
      "processing 2012/08\n",
      "processing 2012/09\n",
      "processing 2012/10\n",
      "processing 2012/11\n",
      "processing 2012/12\n",
      "processing 2013/01\n",
      "processing 2013/02\n",
      "processing 2013/03\n",
      "processing 2013/04\n",
      "processing 2013/05\n",
      "processing 2013/06\n",
      "processing 2013/07\n",
      "processing 2013/08\n",
      "processing 2013/09\n",
      "processing 2013/10\n",
      "processing 2013/11\n",
      "processing 2013/12\n",
      "processing 2014/01\n",
      "processing 2014/02\n",
      "processing 2014/03\n",
      "processing 2014/04\n",
      "processing 2014/05\n",
      "processing 2014/06\n",
      "processing 2014/07\n",
      "processing 2014/08\n",
      "processing 2014/09\n",
      "processing 2014/10\n",
      "processing 2014/11\n",
      "processing 2014/12\n",
      "processing 2015/01\n",
      "processing 2015/02\n",
      "processing 2015/03\n",
      "processing 2015/04\n",
      "processing 2015/05\n",
      "processing 2015/06\n",
      "processing 2015/07\n",
      "processing 2015/08\n",
      "processing 2015/09\n",
      "processing 2015/10\n",
      "processing 2015/11\n",
      "processing 2015/12\n",
      "processing 2016/01\n",
      "processing 2016/02\n",
      "processing 2016/03\n",
      "processing 2016/04\n",
      "processing 2016/05\n",
      "processing 2016/06\n",
      "processing 2016/07\n",
      "processing 2016/08\n",
      "processing 2016/09\n",
      "processing 2016/10\n",
      "processing 2016/11\n",
      "processing 2016/12\n",
      "processing 2017/01\n",
      "processing 2017/02\n",
      "processing 2017/03\n",
      "processing 2017/04\n",
      "processing 2017/05\n",
      "processing 2017/06\n",
      "processing 2017/07\n",
      "processing 2017/08\n",
      "processing 2017/09\n",
      "processing 2017/10\n",
      "processing 2017/11\n",
      "processing 2017/12\n",
      "processing 2018/01\n",
      "processing 2018/02\n",
      "processing 2018/03\n",
      "processing 2018/04\n",
      "processing 2018/05\n",
      "processing 2018/06\n",
      "processing 2018/07\n",
      "processing 2018/08\n",
      "processing 2018/09\n",
      "processing 2018/10\n",
      "processing 2018/11\n",
      "processing 2018/12\n",
      "processing 2019/01\n",
      "processing 2019/02\n",
      "processing 2019/03\n",
      "processing 2019/04\n",
      "processing 2019/05\n",
      "processing 2019/06\n",
      "processing 2019/07\n",
      "processing 2019/08\n",
      "processing 2019/09\n",
      "processing 2019/10\n",
      "processing 2019/11\n",
      "processing 2019/12\n",
      "processing 2020/01\n",
      "processing 2020/02\n",
      "processing 2020/03\n",
      "processing 2020/04\n",
      "processing 2020/05\n",
      "processing 2020/06\n",
      "processing 2020/07\n",
      "processing 2020/08\n",
      "processing 2020/09\n",
      "processing 2020/10\n",
      "processing 2020/11\n",
      "processing 2020/12\n",
      "processing 2021/01\n",
      "processing 2021/02\n",
      "processing 2021/03\n",
      "processing 2021/04\n",
      "processing 2021/05\n",
      "processing 2021/06\n",
      "processing 2021/07\n",
      "processing 2021/08\n",
      "processing 2021/09\n",
      "processing 2021/10\n",
      "processing 2021/11\n",
      "processing 2021/12\n",
      "processing 2022/01\n",
      "processing 2022/02\n",
      "processing 2022/03\n",
      "processing 2022/04\n",
      "processing 2022/05\n",
      "processing 2022/06\n",
      "processing 2022/07\n",
      "processing 2022/08\n",
      "processing 2022/09\n",
      "processing 2022/10\n",
      "processing 2022/11\n",
      "processing 2022/12\n",
      "processing 2023/01\n",
      "processing 2023/02\n",
      "processing 2023/03\n",
      "processing 2023/04\n",
      "processing 2023/05\n",
      "processing 2023/06\n",
      "processing 2023/07\n",
      "processing 2023/08\n",
      "processing 2023/09\n",
      "processing 2023/10\n",
      "processing 2023/11\n",
      "processing 2023/12\n",
      "processing 2024/01\n",
      "processing 2024/02\n",
      "processing 2024/03\n",
      "processing 2024/04\n",
      "processing 2024/05\n",
      "processing 2024/06\n",
      "processing 2024/07\n",
      "processing 2024/08\n",
      "processing 2024/09\n",
      "processing 2024/10\n",
      "processing 2024/11\n",
      "processing 2024/12\n"
     ]
    }
   ],
   "source": [
    "my_dfs = []\n",
    "for year in [\"2009\", \"2010\", \"2011\", \"2012\", \"2013\", \"2014\", \"2015\", \"2016\", \"2017\", \"2018\", \"2019\", \"2020\", \"2021\", \"2022\", \"2023\", \"2024\"]:\n",
    "    if year == \"2025\":\n",
    "        !echo processing {year}/01\n",
    "        my_dfs.append(read(year, \"01\"))\n",
    "        !echo processing {year}/02\n",
    "        my_dfs.append(read(year, \"02\"))\n",
    "    else:\n",
    "        for month in [\"01\", \"02\", \"03\", \"04\", \"05\", \"06\", \"07\", \"08\", \"09\", \"10\", \"11\", \"12\"]:\n",
    "            !echo processing {year}/{month}\n",
    "            my_dfs.append(read(year, month))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dbbc118d-bec6-4ac9-89f5-be4347d4d4fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "from pyspark.sql import DataFrame\n",
    "\n",
    "df = reduce(DataFrame.unionAll, my_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67574d2c-f2a9-4c46-a6a5-41a1c9338e5d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/12 15:10:48 WARN DAGScheduler: Broadcasting large task binary with size 2.9 MiB\n",
      "25/04/12 15:10:48 WARN DAGScheduler: Broadcasting large task binary with size 2.9 MiB\n",
      "25/04/12 15:10:48 WARN DAGScheduler: Broadcasting large task binary with size 2.9 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+---------------+-----------------+------------+----------+------------+----+-----+-----------+\n",
      "|    pickup_datetime|   dropoff_datetime|passenger_count|    trip_distance|payment_type|tip_amount|total_amount|year|month|trip_amount|\n",
      "+-------------------+-------------------+---------------+-----------------+------------+----------+------------+----+-----+-----------+\n",
      "|2009-01-04 02:52:00|2009-01-04 03:02:00|              1|        4.2325642|           2|       0.0|         9.4|2009|   01|        9.4|\n",
      "|2009-01-04 03:31:00|2009-01-04 03:38:00|              3|7.322496999999999|           1|       2.0|        14.6|2009|   01|       12.6|\n",
      "+-------------------+-------------------+---------------+-----------------+------------+----------+------------+----+-----+-----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d84ebb9-8d2d-411d-be48-b1e74bd1fe67",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- pickup_datetime: timestamp (nullable = true)\n",
      " |-- dropoff_datetime: timestamp (nullable = true)\n",
      " |-- passenger_count: long (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- payment_type: string (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- year: string (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      " |-- trip_amount: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "277f5af9-66aa-4c9e-a669-2506b36e981e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df.selectExpr(\\\n",
    "    \"cast(year as int)\", \\\n",
    "    \"cast(month as int)\", \\\n",
    "    \"pickup_datetime\", \\\n",
    "    \"dropoff_datetime\", \\\n",
    "    \"passenger_count\", \\\n",
    "    \"trip_distance\", \\\n",
    "    \"payment_type\", \\\n",
    "    \"tip_amount\", \\\n",
    "    \"trip_amount\", \\\n",
    "    \"total_amount\" \\\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "646289b2-230a-4af2-b341-5b64a5b7b03d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- pickup_datetime: timestamp (nullable = true)\n",
      " |-- dropoff_datetime: timestamp (nullable = true)\n",
      " |-- passenger_count: long (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- payment_type: string (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- trip_amount: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c7e0d64b-a249-4d64-8aa2-49b590a8eb53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|min(pickup_datetime)|\n",
      "+--------------------+\n",
      "| 2001-01-01 00:01:48|\n",
      "+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|max(pickup_datetime)|\n",
      "+--------------------+\n",
      "| 2098-09-11 02:23:31|\n",
      "+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+\n",
      "|min(dropoff_datetime)|\n",
      "+---------------------+\n",
      "|  1900-01-01 00:00:00|\n",
      "+---------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 220:=================================================>(5766 + 23) / 5789]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+\n",
      "|max(dropoff_datetime)|\n",
      "+---------------------+\n",
      "|  2253-08-23 07:56:38|\n",
      "+---------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Suppose you have a DataFrame called df\n",
    "df.select(F.min(\"pickup_datetime\")).show()\n",
    "df.select(F.max(\"pickup_datetime\")).show()\n",
    "df.select(F.min(\"dropoff_datetime\")).show()\n",
    "df.select(F.max(\"dropoff_datetime\")).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9194a58a-6dff-4537-a048-88c4d67877d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/plain": [
       "1778238040"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "23cf23ef-49cb-46a6-a0d8-aa9ce8c4fba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "\n",
    "filtered_df = df\\\n",
    "    .filter(col(\"pickup_datetime\") < lit(\"2024-12-31\")) \\\n",
    "    .filter(col(\"pickup_datetime\") > lit(\"2009-01-01\")) \\\n",
    "    .filter(col(\"dropoff_datetime\") < lit(\"2024-12-31\")) \\\n",
    "    .filter(col(\"dropoff_datetime\") > lit(\"2009-01-01\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5f52deea-e9e9-4750-95f6-985c6aad2a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/12 15:11:58 WARN DAGScheduler: Broadcasting large task binary with size 1426.6 KiB\n",
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/plain": [
       "1778147044"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "78c933b0-c5ca-4921-9871-babdbd174065",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/12 15:12:28 WARN DAGScheduler: Broadcasting large task binary with size 3.2 MiB\n",
      "25/04/12 15:12:29 WARN DAGScheduler: Broadcasting large task binary with size 3.2 MiB\n",
      "25/04/12 15:12:29 WARN DAGScheduler: Broadcasting large task binary with size 3.2 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-------------------+-------------------+---------------+------------------+------------+----------+------------------+------------+\n",
      "|year|month|    pickup_datetime|   dropoff_datetime|passenger_count|     trip_distance|payment_type|tip_amount|       trip_amount|total_amount|\n",
      "+----+-----+-------------------+-------------------+---------------+------------------+------------+----------+------------------+------------+\n",
      "|2009|    1|2009-01-04 02:52:00|2009-01-04 03:02:00|              1|         4.2325642|           2|       0.0|               9.4|         9.4|\n",
      "|2009|    1|2009-01-04 03:31:00|2009-01-04 03:38:00|              3| 7.322496999999999|           1|       2.0|              12.6|        14.6|\n",
      "|2009|    1|2009-01-03 15:43:00|2009-01-03 15:57:00|              5|         16.656669|           1|      4.74|23.700000000000003|       28.44|\n",
      "|2009|    1|2009-01-01 20:52:58|2009-01-01 21:14:00|              1|            8.0467|           1|      3.05|15.399999999999999|       18.45|\n",
      "|2009|    1|2009-01-24 16:18:23|2009-01-24 16:24:56|              1|0.6437360000000001|           2|       0.0|               3.7|         3.7|\n",
      "|2009|    1|2009-01-16 22:35:59|2009-01-16 22:43:35|              2|1.9312079999999998|           2|       0.0|               6.6|         6.6|\n",
      "|2009|    1|2009-01-21 08:55:57|2009-01-21 09:05:42|              1|0.6437360000000001|           1|       1.0|               5.7|         6.7|\n",
      "|2009|    1|2009-01-04 04:31:00|2009-01-04 04:36:00|              1|         2.7680648|           2|       0.0|               6.6|         6.6|\n",
      "|2009|    1|2009-01-05 16:29:02|2009-01-05 16:40:21|              1|2.5749440000000003|           1|       1.3|               8.7|        10.0|\n",
      "|2009|    1|2009-01-05 18:53:13|2009-01-05 18:57:45|              1|1.1265379999999998|           2|       0.0|               5.9|         5.9|\n",
      "|2009|    1|2009-01-05 08:15:38|2009-01-05 08:16:44|              1|0.4828019999999998|           2|       0.0|               2.9|         2.9|\n",
      "|2009|    1|2009-01-05 06:21:43|2009-01-05 06:28:41|              1|3.7014819999999995|           2|       0.0|               7.7|         7.7|\n",
      "|2009|    1|2009-01-20 13:44:02|2009-01-20 13:52:43|              2|          3.379614|           2|       0.0|               7.3|         7.3|\n",
      "|2009|    1|2009-01-05 16:19:53|2009-01-05 16:26:48|              2|1.9312079999999998|           2|       0.0|               6.7|         6.7|\n",
      "|2009|    1|2009-01-05 17:22:16|2009-01-05 17:27:25|              1|1.2874720000000002|           2|       0.0|               5.9|         5.9|\n",
      "|2009|    1|2009-01-05 16:02:52|2009-01-05 16:18:43|              1|           7.24203|           2|       0.0|              13.9|        13.9|\n",
      "|2009|    1|2009-01-05 12:15:06|2009-01-05 12:27:58|              1|          2.735878|           2|       0.0|               8.5|         8.5|\n",
      "|2009|    1|2009-01-05 07:49:57|2009-01-05 07:54:11|              1|           1.60934|           1|       1.0|               4.5|         5.5|\n",
      "|2009|    1|2009-01-23 23:57:34|2009-01-24 00:12:40|              2|            8.0467|           1|      3.45|              13.8|       17.25|\n",
      "|2009|    1|2009-01-05 10:23:13|2009-01-05 10:33:56|              1|          2.092142|           2|       0.0|               7.3|         7.3|\n",
      "+----+-----+-------------------+-------------------+---------------+------------------+------------+----------+------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filtered_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cffe595-969f-493e-9da6-7f016dc145c6",
   "metadata": {},
   "source": [
    "## Write results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5f5dedb1-79c2-4838-9058-1fb8ff264892",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted /taxi/raw_all.parquet\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -rm -r /taxi/raw_all.parquet/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2dcc38-9295-43fb-815f-8f8a113da4c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filtered_df.repartition(44).write.parquet(f\"/taxi/raw_all.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e594447-2f64-4cff-8df0-ee561ef19922",
   "metadata": {},
   "source": [
    "## Stopping Spark "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f73b43fe-0bc6-4c72-89af-43dd22bba8f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
